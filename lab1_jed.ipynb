{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "702dc4bf-0fe7-425c-b040-b1fa0535474d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T12:43:12.893447Z",
     "iopub.status.busy": "2024-05-05T12:43:12.893210Z",
     "iopub.status.idle": "2024-05-05T12:43:13.268617Z",
     "shell.execute_reply": "2024-05-05T12:43:13.267769Z",
     "shell.execute_reply.started": "2024-05-05T12:43:12.893422Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# import zipfile\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5313af64-34ef-44f9-8ebc-5cab99746fef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T12:43:13.907628Z",
     "iopub.status.busy": "2024-05-05T12:43:13.906977Z",
     "iopub.status.idle": "2024-05-05T12:43:17.553469Z",
     "shell.execute_reply": "2024-05-05T12:43:17.551986Z",
     "shell.execute_reply.started": "2024-05-05T12:43:13.907568Z"
    }
   },
   "outputs": [],
   "source": [
    "spark = (SparkSession\n",
    "     .builder\n",
    "     .master('local[*]') # Master URL;\n",
    "     .getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1137579d-3de8-462b-b437-3ff573c401ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T12:43:18.373164Z",
     "iopub.status.busy": "2024-05-05T12:43:18.371898Z",
     "iopub.status.idle": "2024-05-05T12:49:00.112218Z",
     "shell.execute_reply": "2024-05-05T12:49:00.109633Z",
     "shell.execute_reply.started": "2024-05-05T12:43:18.373094Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:KeyboardInterrupt while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/socket.py\", line 706, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7f3a98d89290>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 770, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 36\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Define the schema—NOT FINAL; SHOULD REVISIT\u001b[39;00m\n\u001b[1;32m      6\u001b[0m schema \u001b[38;5;241m=\u001b[39m StructType([\n\u001b[1;32m      7\u001b[0m     StructField(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGKGRECORDID\u001b[39m\u001b[38;5;124m\"\u001b[39m, StringType(), \u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m      8\u001b[0m     StructField(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mV2.1DATE\u001b[39m\u001b[38;5;124m\"\u001b[39m, LongType(), \u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     33\u001b[0m     StructField(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mV2EXTRASXML\u001b[39m\u001b[38;5;124m\"\u001b[39m, StringType(), \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     34\u001b[0m ])\n\u001b[0;32m---> 36\u001b[0m df_gkg \u001b[38;5;241m=\u001b[39m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcsv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/mnt/data/public/gdeltv2/gkg/201908*.gkg.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m                        \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/readwriter.py:740\u001b[0m, in \u001b[0;36mDataFrameReader.csv\u001b[0;34m(self, path, schema, sep, encoding, quote, escape, comment, header, inferSchema, ignoreLeadingWhiteSpace, ignoreTrailingWhiteSpace, nullValue, nanValue, positiveInf, negativeInf, dateFormat, timestampFormat, maxColumns, maxCharsPerColumn, maxMalformedLogPerPartition, mode, columnNameOfCorruptRecord, multiLine, charToEscapeQuoteEscaping, samplingRatio, enforceSchema, emptyValue, locale, lineSep, pathGlobFilter, recursiveFileLookup, modifiedBefore, modifiedAfter, unescapedQuoteHandling)\u001b[0m\n\u001b[1;32m    738\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(path) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlist\u001b[39m:\n\u001b[1;32m    739\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_spark\u001b[38;5;241m.\u001b[39m_sc\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 740\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_df(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jreader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcsv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_spark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPythonUtils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoSeq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    741\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, RDD):\n\u001b[1;32m    743\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunc\u001b[39m(iterator):\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1314\u001b[0m args_command, temp_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_args(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m-> 1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[1;32m   1323\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1038\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1036\u001b[0m connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_connection()\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1038\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1039\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m binary:\n\u001b[1;32m   1040\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_connection_guard(connection)\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:511\u001b[0m, in \u001b[0;36mClientServerConnection.send_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 511\u001b[0m         answer \u001b[38;5;241m=\u001b[39m smart_decode(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream\u001b[38;5;241m.\u001b[39mreadline()[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    512\u001b[0m         logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnswer received: \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(answer))\n\u001b[1;32m    513\u001b[0m         \u001b[38;5;66;03m# Happens when a the other end is dead. There might be an empty\u001b[39;00m\n\u001b[1;32m    514\u001b[0m         \u001b[38;5;66;03m# answer before the socket raises an error.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 706\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    708\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import (StructType, StructField, StringType,\n",
    "IntegerType, FloatType, TimestampType, LongType)\n",
    "import glob\n",
    "\n",
    "# Define the schema—NOT FINAL; SHOULD REVISIT\n",
    "schema = StructType([\n",
    "    StructField(\"GKGRECORDID\", StringType(), True),\n",
    "    StructField(\"V2.1DATE\", LongType(), True),\n",
    "    StructField(\"V2SOURCECOLLECTIONIDENTIFIER\", IntegerType(), True),\n",
    "    StructField(\"V2SOURCECOMMONNAME\", StringType(), True),\n",
    "    StructField(\"V2DOCUMENTIDENTIFIER\", StringType(), True),\n",
    "    StructField(\"V1COUNTS\", StringType(), True),\n",
    "    StructField(\"V2.1COUNTS\", StringType(), True),\n",
    "    StructField(\"V1THEMES\", StringType(), True),\n",
    "    StructField(\"V2ENHANCEDTHEMES\", StringType(), True),\n",
    "    StructField(\"V1LOCATIONS\", StringType(), True),\n",
    "    StructField(\"V2ENHANCEDLOCATIONS\", StringType(), True),\n",
    "    StructField(\"V1PERSONS\", StringType(), True),\n",
    "    StructField(\"V2ENHANCEDPERSONS\", StringType(), True),\n",
    "    StructField(\"V1ORGANIZATIONS\", StringType(), True),\n",
    "    StructField(\"V2ENHANCEDORGANIZATIONS\", StringType(), True),\n",
    "    StructField(\"V1.5TONE\", FloatType(), True),\n",
    "    StructField(\"V2.1ENHANCEDDATES\", StringType(), True),\n",
    "    StructField(\"V2GCAM\", StringType(), True),\n",
    "    StructField(\"V2.1SHARINGIMAGE\", StringType(), True),\n",
    "    StructField(\"V2.1RELATEDIMAGES\", StringType(), True),\n",
    "    StructField(\"V2.1SOCIALIMAGEEMBEDS\", StringType(), True),\n",
    "    StructField(\"V2.1SOCIALVIDEOEMBEDS\", StringType(), True),\n",
    "    StructField(\"V2.1QUOTATIONS\", StringType(), True),\n",
    "    StructField(\"V2.1ALLNAMES\", StringType(), True),\n",
    "    StructField(\"V2.1AMOUNTS\", StringType(), True),\n",
    "    StructField(\"V2.1TRANSLATIONINFO\", StringType(), True),\n",
    "    StructField(\"V2EXTRASXML\", StringType(), True)\n",
    "])\n",
    "\n",
    "df_gkg = spark.read.csv('/mnt/data/public/gdeltv2/gkg/201908*.gkg.csv',\n",
    "                        sep='\\t', schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8d81cb-41e0-4753-b52e-eab3c2fcfda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gkg.limit(3).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02cab0d-c411-41eb-9dbb-efd518bc79a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_gkg\n",
    " .withColumn('LOCATION', F.regexp_extract('V1COUNTS',r\",\\s*([^,#]+)#\", 1))\n",
    " .filter(F.col('LOCATION').rlike('Philippines'))\n",
    " .count()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a03e9e9-b545-4e83-9e0b-f383b930a211",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "\n",
    "def calculate_and_print_total_size_per_week_of_august(directory, year):\n",
    "    \"\"\"\n",
    "    Calculate and print the total file size of files for each week of August of a specified year.\n",
    "\n",
    "    Parameters:\n",
    "        directory (str): The directory containing the files.\n",
    "        year (int): The year for which files are considered for the month of August.\n",
    "\n",
    "    Returns:\n",
    "        None: Prints the total size per week directly.\n",
    "    \"\"\"\n",
    "    # Define year as a string for matching\n",
    "    year_str = str(year)\n",
    "    \n",
    "    # Initialize dictionary to hold file sizes for each week of August\n",
    "    weekly_sizes = {week: 0 for week in range(1, 6)}\n",
    "\n",
    "    # List files in the directory\n",
    "    try:\n",
    "        files = os.listdir(directory)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Directory not found: {directory}\")\n",
    "        return\n",
    "\n",
    "    # Filter and accumulate file sizes for each week of August\n",
    "    for file in files:\n",
    "        if file.endswith('.gkg.csv') and file.startswith(year_str + '08'):\n",
    "            # Extract the date from the filename (assuming format YYYYMMDD)\n",
    "            date_str = file[:8]  # YYYYMMDD\n",
    "            date_obj = datetime.datetime.strptime(date_str, '%Y%m%d')\n",
    "            week_of_month = (date_obj.day - 1) // 7 + 1\n",
    "            \n",
    "            # Construct the full file path\n",
    "            file_path = os.path.join(directory, file)\n",
    "            # Add the file size in bytes to the total for the week\n",
    "            weekly_sizes[week_of_month] += os.stat(file_path).st_size\n",
    "\n",
    "    # Print the results for each week\n",
    "    for week in range(1, 6):\n",
    "        total_size_bytes = weekly_sizes[week]\n",
    "        total_size_mb = total_size_bytes / (1024**2)\n",
    "        total_size_gb = total_size_bytes / (1024**3)\n",
    "        print(f\"Total size for {year}-08, week {week}: {total_size_bytes} bytes, {total_size_mb:.2f} MB, {total_size_gb:.2f} GB\")\n",
    "\n",
    "# Example usage\n",
    "directory = '/mnt/data/public/gdeltv2/gkg'\n",
    "year = 2019\n",
    "calculate_and_print_total_size_per_week_of_august(directory, year)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
